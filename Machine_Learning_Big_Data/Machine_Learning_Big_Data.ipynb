{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Machine Learning in Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1 Data Loading and exploration</h2>\n",
    "<h3>1.1 Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext # Spark\n",
    "from pyspark.sql import SparkSession # Spark SQL\n",
    "\n",
    "# local[*]: run Spark in local mode with as many working processors as logical cores on my machine\n",
    "master = \"local[*]\"\n",
    "# Set the appname\n",
    "app_name = \"Building models to predict pedestrian traffic\"\n",
    "# Setup configuration parameters for Spark\n",
    "spark_conf = SparkConf().setMaster(master).setAppName(app_name).set(\"spark.sql.session.timeZone\", \"UTC\")\n",
    "print(spark_conf.toDebugString())\n",
    "\n",
    "# Using SparkSession\n",
    "spark = SparkSession.builder.config(conf=spark_conf).getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, FloatType, TimestampType\n",
    "\n",
    "# defining the Monthly counts data schema\n",
    "montly_counts_schema = StructType([StructField(\"ID\",IntegerType(),False), \n",
    "                                   StructField(\"Date_Time\", StringType(),False), \n",
    "                                   StructField(\"Year\", IntegerType(),True), \n",
    "                                   StructField(\"Month\", StringType(),True), \n",
    "                                   StructField(\"Mdate\", IntegerType(),True), \n",
    "                                   StructField(\"Day\", StringType(),True), \n",
    "                                   StructField(\"Time\", IntegerType(),True),\n",
    "                                   StructField(\"Sensor_ID\", IntegerType(),True),\n",
    "                                   StructField(\"Sensor_Name\", StringType(),True),\n",
    "                                   StructField(\"Hourly_Counts\", IntegerType(),True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Date_Time: timestamp (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: string (nullable = true)\n",
      " |-- Mdate: integer (nullable = true)\n",
      " |-- Day: string (nullable = true)\n",
      " |-- Time: integer (nullable = true)\n",
      " |-- Sensor_ID: integer (nullable = true)\n",
      " |-- Sensor_Name: string (nullable = true)\n",
      " |-- Hourly_Counts: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "# function to read csv into df with a given schema\n",
    "def readCsvToDf(filename:str, schema):\n",
    "    df = spark.read.format(\"csv\").option(\"header\", \"true\").schema(schema).load(filename)\n",
    "    df = df.withColumn(\"Date_Time\",to_timestamp(col(\"Date_Time\"), \"MM/dd/yyyy hh:mm:ss a\").alias(\"Date_Time\"))\n",
    "    df = df.withColumn(\"Date_Time\",col(\"Date_Time\").cast(TimestampType()))\n",
    "    df.printSchema()\n",
    "    return df\n",
    "\n",
    "# load pedestrian count CSV file into a dataframe\n",
    "ped_counts_df = readCsvToDf(\"Pedestrian_Counting_System_-_Monthly__counts_per_hour.csv\", montly_counts_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Date_Time: timestamp (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: string (nullable = true)\n",
      " |-- Mdate: integer (nullable = true)\n",
      " |-- Day: string (nullable = true)\n",
      " |-- Time: integer (nullable = true)\n",
      " |-- Sensor_ID: integer (nullable = true)\n",
      " |-- Sensor_Name: string (nullable = true)\n",
      " |-- Hourly_Counts: integer (nullable = true)\n",
      " |-- above_threshold: double (nullable = false)\n",
      "\n",
      "+-------+-------------------+----+--------+-----+------+----+---------+--------------------+-------------+---------------+\n",
      "|     ID|          Date_Time|Year|   Month|Mdate|   Day|Time|Sensor_ID|         Sensor_Name|Hourly_Counts|above_threshold|\n",
      "+-------+-------------------+----+--------+-----+------+----+---------+--------------------+-------------+---------------+\n",
      "|2887628|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       34|Flinders St-Spark La|          300|            0.0|\n",
      "|2887629|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       39|        Alfred Place|          604|            0.0|\n",
      "|2887630|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       37|     Lygon St (East)|          216|            0.0|\n",
      "|2887631|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       40|Lonsdale St-Sprin...|          627|            0.0|\n",
      "|2887632|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       36|     Queen St (West)|          774|            0.0|\n",
      "|2887633|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       29|St Kilda Rd-Alexa...|          644|            0.0|\n",
      "|2887634|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       42|Grattan St-Swanst...|          453|            0.0|\n",
      "|2887635|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       43|Monash Rd-Swansto...|          387|            0.0|\n",
      "|2887636|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       44|Tin Alley-Swansto...|           27|            0.0|\n",
      "|2887637|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       35|           Southbank|         2691|            1.0|\n",
      "|2887638|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       45|Little Collins St...|         2173|            1.0|\n",
      "+-------+-------------------+----+--------+-----+------+----+---------+--------------------+-------------+---------------+\n",
      "only showing top 11 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "ped_counts_df = ped_counts_df.withColumn('above_threshold', when(col('Hourly_Counts') >= 2000, 1.0).otherwise(0.0))\n",
    "ped_counts_df.printSchema()\n",
    "ped_counts_df.show(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+------------------+------------------+-----------------+\n",
      "|summary|               ID|              Year|             Mdate|              Time|         Sensor_ID|    Hourly_Counts|\n",
      "+-------+-----------------+------------------+------------------+------------------+------------------+-----------------+\n",
      "|  count|          3435106|           3435106|           3435106|           3435106|           3435106|          3435106|\n",
      "|   mean|        1717553.5|2016.0032330880038|15.751918863639142|11.459955238644746|22.978422791028866|560.7805942524044|\n",
      "| stddev|991629.8312350252|3.1237869143646275|  8.79918757461428| 6.943473866829414|16.229792156265397|809.9942576353371|\n",
      "|    min|                1|              2009|                 1|                 0|                 1|                0|\n",
      "|    max|          3435106|              2020|                31|                23|                71|            15979|\n",
      "|    25%|              1.0|            2009.0|               1.0|               0.0|               1.0|              0.0|\n",
      "|    50%|        2325691.0|            2018.0|              16.0|              11.0|              24.0|            248.0|\n",
      "|    75%|        3435106.0|            2020.0|              31.0|              23.0|              71.0|          15979.0|\n",
      "+-------+-----------------+------------------+------------------+------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# concatenate the arrays within an array to just an array within an array\n",
    "def concatenate_array(array):\n",
    "    for i in range(1, len(array)):\n",
    "        array[0] += array[i]\n",
    "    return array[0]\n",
    "\n",
    "columns_without_thres_datetime = [\"ID\", \"Year\", \"Mdate\", \"Time\", \"Sensor_ID\", \"Hourly_Counts\"]\n",
    "# Get the count mean, stddev, min and max\n",
    "stats_df = ped_counts_df.select(columns_without_thres_datetime).describe()\n",
    "\n",
    "quantiles = [0.25,0.50,0.75]\n",
    "all_quantiles = []\n",
    "\n",
    "# get the 25,50,75 percentiles\n",
    "for i in range(len(quantiles)):\n",
    "    quantile = quantiles[i]\n",
    "    # get the quantile\n",
    "    quantile_stats = ped_counts_df.approxQuantile(columns_without_thres_datetime, [quantile], 0.25)\n",
    "    quantile_stats = concatenate_array(quantile_stats)\n",
    "    # create summary title\n",
    "    title = str(quantile)[2:]\n",
    "    if len(title) < 2:\n",
    "        title += \"0\"\n",
    "    quantile_stats.insert(0, title+\"%\")\n",
    "    all_quantiles.append(quantile_stats)\n",
    "\n",
    "# create data frame rows of quantiles values\n",
    "quantiles_df = spark.createDataFrame(all_quantiles)\n",
    "\n",
    "# merge the percentiles rows with the stats dataframe\n",
    "stats_df = stats_df.union(quantiles_df)\n",
    "stats_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+\n",
      "|above_threshold|  count|\n",
      "+---------------+-------+\n",
      "|            0.0|3184164|\n",
      "|            1.0| 250942|\n",
      "+---------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ped_counts_df.groupby(\"above_threshold\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Feature extraction and ML training\n",
    "<h3>2.1 Preparing Spark ML Transformers/Estimators for features, labels and models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+----+--------+-----+------+----+---------+--------------------+-------------+---------------+-------------+-----------+------------+-----+\n",
      "|     ID|          Date_Time|Year|   Month|Mdate|   Day|Time|Sensor_ID|         Sensor_Name|Hourly_Counts|above_threshold|Month_Integer|day_of_week|week_of_year|label|\n",
      "+-------+-------------------+----+--------+-----+------+----+---------+--------------------+-------------+---------------+-------------+-----------+------------+-----+\n",
      "|2887628|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       34|Flinders St-Spark La|          300|            0.0|           11|          5|          44|  0.0|\n",
      "|2887629|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       39|        Alfred Place|          604|            0.0|           11|          5|          44|  0.0|\n",
      "|2887630|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       37|     Lygon St (East)|          216|            0.0|           11|          5|          44|  0.0|\n",
      "|2887631|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       40|Lonsdale St-Sprin...|          627|            0.0|           11|          5|          44|  0.0|\n",
      "|2887632|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       36|     Queen St (West)|          774|            0.0|           11|          5|          44|  0.0|\n",
      "|2887633|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       29|St Kilda Rd-Alexa...|          644|            0.0|           11|          5|          44|  0.0|\n",
      "|2887634|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       42|Grattan St-Swanst...|          453|            0.0|           11|          5|          44|  0.0|\n",
      "|2887635|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       43|Monash Rd-Swansto...|          387|            0.0|           11|          5|          44|  0.0|\n",
      "|2887636|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       44|Tin Alley-Swansto...|           27|            0.0|           11|          5|          44|  0.0|\n",
      "|2887637|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       35|           Southbank|         2691|            1.0|           11|          5|          44|  1.0|\n",
      "|2887638|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       45|Little Collins St...|         2173|            1.0|           11|          5|          44|  1.0|\n",
      "|2887639|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       46|       Pelham St (S)|          203|            0.0|           11|          5|          44|  0.0|\n",
      "|2887640|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       47|Melbourne Central...|         2354|            1.0|           11|          5|          44|  1.0|\n",
      "|2887641|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       48| QVM-Queen St (East)|          358|            0.0|           11|          5|          44|  0.0|\n",
      "|2887642|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       49|QVM-Therry St (So...|          161|            0.0|           11|          5|          44|  0.0|\n",
      "|2887643|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       50|Faraday St-Lygon ...|          502|            0.0|           11|          5|          44|  0.0|\n",
      "|2887644|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       51|QVM-Franklin St (...|          159|            0.0|           11|          5|          44|  0.0|\n",
      "|2887645|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       52|Elizabeth St-Lons...|          914|            0.0|           11|          5|          44|  0.0|\n",
      "|2887646|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       54|Lincoln-Swanston(...|          276|            0.0|           11|          5|          44|  0.0|\n",
      "|2887647|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       55|Elizabeth St-La T...|         2070|            1.0|           11|          5|          44|  1.0|\n",
      "|2887648|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       56|Lonsdale St - Eli...|          789|            0.0|           11|          5|          44|  0.0|\n",
      "|2887649|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       57|    Bourke St Bridge|         2122|            1.0|           11|          5|          44|  1.0|\n",
      "|2887650|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       58|Bourke St - Spenc...|         2528|            1.0|           11|          5|          44|  1.0|\n",
      "|2887651|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       59|Swanston St - RMI...|          485|            0.0|           11|          5|          44|  0.0|\n",
      "|2887652|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       61|Swanston St - RMI...|         1240|            0.0|           11|          5|          44|  0.0|\n",
      "|2887653|2019-11-01 17:00:00|2019|November|    1|Friday|  17|       62| La Trobe St (North)|          229|            0.0|           11|          5|          44|  0.0|\n",
      "|2887654|2019-11-01 18:00:00|2019|November|    1|Friday|  18|        4|    Town Hall (West)|         2950|            1.0|           11|          5|          44|  1.0|\n",
      "|2887655|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       17|Collins Place (So...|          646|            0.0|           11|          5|          44|  0.0|\n",
      "|2887656|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       18|Collins Place (No...|          626|            0.0|           11|          5|          44|  0.0|\n",
      "|2887657|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       53|  Collins St (North)|         1153|            0.0|           11|          5|          44|  0.0|\n",
      "|2887658|2019-11-01 18:00:00|2019|November|    1|Friday|  18|        2|Bourke Street Mal...|         2226|            1.0|           11|          5|          44|  1.0|\n",
      "|2887659|2019-11-01 18:00:00|2019|November|    1|Friday|  18|        1|Bourke Street Mal...|         3183|            1.0|           11|          5|          44|  1.0|\n",
      "|2887660|2019-11-01 18:00:00|2019|November|    1|Friday|  18|        3|   Melbourne Central|         2802|            1.0|           11|          5|          44|  1.0|\n",
      "|2887661|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       15|       State Library|         1904|            0.0|           11|          5|          44|  0.0|\n",
      "|2887662|2019-11-01 18:00:00|2019|November|    1|Friday|  18|        9|Southern Cross St...|         1310|            0.0|           11|          5|          44|  0.0|\n",
      "|2887663|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       10|      Victoria Point|          147|            0.0|           11|          5|          44|  0.0|\n",
      "|2887664|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       12|            New Quay|          424|            0.0|           11|          5|          44|  0.0|\n",
      "|2887665|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       11|     Waterfront City|           90|            0.0|           11|          5|          44|  0.0|\n",
      "|2887666|2019-11-01 18:00:00|2019|November|    1|Friday|  18|        8|         Webb Bridge|          301|            0.0|           11|          5|          44|  0.0|\n",
      "|2887667|2019-11-01 18:00:00|2019|November|    1|Friday|  18|        7|      Birrarung Marr|         1010|            0.0|           11|          5|          44|  0.0|\n",
      "|2887668|2019-11-01 18:00:00|2019|November|    1|Friday|  18|        5|      Princes Bridge|         3084|            1.0|           11|          5|          44|  1.0|\n",
      "|2887669|2019-11-01 18:00:00|2019|November|    1|Friday|  18|        6|Flinders Street S...|         3462|            1.0|           11|          5|          44|  1.0|\n",
      "|2887670|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       14|    Sandridge Bridge|           43|            0.0|           11|          5|          44|  0.0|\n",
      "|2887671|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       26|QV Market-Elizabe...|          744|            0.0|           11|          5|          44|  0.0|\n",
      "|2887672|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       24|Spencer St-Collin...|         2552|            1.0|           11|          5|          44|  1.0|\n",
      "|2887673|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       23|Spencer St-Collin...|          496|            0.0|           11|          5|          44|  0.0|\n",
      "|2887674|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       25|Melbourne Convent...|         2355|            1.0|           11|          5|          44|  1.0|\n",
      "|2887675|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       21|Bourke St-Russell...|         1071|            0.0|           11|          5|          44|  0.0|\n",
      "|2887676|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       20|Chinatown-Lt Bour...|          816|            0.0|           11|          5|          44|  0.0|\n",
      "|2887677|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       19|Chinatown-Swansto...|         1362|            0.0|           11|          5|          44|  0.0|\n",
      "|2887678|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       22|Flinders St-Eliza...|         3005|            1.0|           11|          5|          44|  1.0|\n",
      "|2887679|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       27|   QV Market-Peel St|          159|            0.0|           11|          5|          44|  0.0|\n",
      "|2887680|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       28|     The Arts Centre|         1565|            0.0|           11|          5|          44|  0.0|\n",
      "|2887681|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       31|     Lygon St (West)|          418|            0.0|           11|          5|          44|  0.0|\n",
      "|2887682|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       30| Lonsdale St (South)|         1129|            0.0|           11|          5|          44|  0.0|\n",
      "|2887683|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       34|Flinders St-Spark La|          240|            0.0|           11|          5|          44|  0.0|\n",
      "|2887684|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       39|        Alfred Place|          384|            0.0|           11|          5|          44|  0.0|\n",
      "|2887685|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       37|     Lygon St (East)|          210|            0.0|           11|          5|          44|  0.0|\n",
      "|2887686|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       40|Lonsdale St-Sprin...|          387|            0.0|           11|          5|          44|  0.0|\n",
      "|2887687|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       36|     Queen St (West)|          496|            0.0|           11|          5|          44|  0.0|\n",
      "|2887688|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       29|St Kilda Rd-Alexa...|          754|            0.0|           11|          5|          44|  0.0|\n",
      "|2887689|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       42|Grattan St-Swanst...|          447|            0.0|           11|          5|          44|  0.0|\n",
      "|2887690|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       43|Monash Rd-Swansto...|          145|            0.0|           11|          5|          44|  0.0|\n",
      "|2887691|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       44|Tin Alley-Swansto...|           25|            0.0|           11|          5|          44|  0.0|\n",
      "|2887692|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       35|           Southbank|         2292|            1.0|           11|          5|          44|  1.0|\n",
      "|2887693|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       45|Little Collins St...|         1927|            0.0|           11|          5|          44|  0.0|\n",
      "|2887694|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       46|       Pelham St (S)|          201|            0.0|           11|          5|          44|  0.0|\n",
      "|2887695|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       47|Melbourne Central...|         1933|            0.0|           11|          5|          44|  0.0|\n",
      "|2887696|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       48| QVM-Queen St (East)|          273|            0.0|           11|          5|          44|  0.0|\n",
      "|2887697|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       49|QVM-Therry St (So...|          150|            0.0|           11|          5|          44|  0.0|\n",
      "|2887698|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       50|Faraday St-Lygon ...|          624|            0.0|           11|          5|          44|  0.0|\n",
      "|2887699|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       51|QVM-Franklin St (...|          181|            0.0|           11|          5|          44|  0.0|\n",
      "|2887700|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       52|Elizabeth St-Lons...|          806|            0.0|           11|          5|          44|  0.0|\n",
      "|2887701|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       54|Lincoln-Swanston(...|          178|            0.0|           11|          5|          44|  0.0|\n",
      "|2887702|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       55|Elizabeth St-La T...|         1972|            0.0|           11|          5|          44|  0.0|\n",
      "|2887703|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       56|Lonsdale St - Eli...|          598|            0.0|           11|          5|          44|  0.0|\n",
      "|2887704|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       57|    Bourke St Bridge|          870|            0.0|           11|          5|          44|  0.0|\n",
      "|2887705|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       58|Bourke St - Spenc...|         1499|            0.0|           11|          5|          44|  0.0|\n",
      "|2887706|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       59|Swanston St - RMI...|          396|            0.0|           11|          5|          44|  0.0|\n",
      "|2887707|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       61|Swanston St - RMI...|         1080|            0.0|           11|          5|          44|  0.0|\n",
      "|2887708|2019-11-01 18:00:00|2019|November|    1|Friday|  18|       62| La Trobe St (North)|          262|            0.0|           11|          5|          44|  0.0|\n",
      "|2887709|2019-11-01 19:00:00|2019|November|    1|Friday|  19|        4|    Town Hall (West)|         2345|            1.0|           11|          5|          44|  1.0|\n",
      "|2887710|2019-11-01 19:00:00|2019|November|    1|Friday|  19|       17|Collins Place (So...|          367|            0.0|           11|          5|          44|  0.0|\n",
      "|2887711|2019-11-01 19:00:00|2019|November|    1|Friday|  19|       18|Collins Place (No...|          294|            0.0|           11|          5|          44|  0.0|\n",
      "|2887712|2019-11-01 19:00:00|2019|November|    1|Friday|  19|       53|  Collins St (North)|          784|            0.0|           11|          5|          44|  0.0|\n",
      "|2887713|2019-11-01 19:00:00|2019|November|    1|Friday|  19|        2|Bourke Street Mal...|         1639|            0.0|           11|          5|          44|  0.0|\n",
      "|2887714|2019-11-01 19:00:00|2019|November|    1|Friday|  19|        1|Bourke Street Mal...|         2533|            1.0|           11|          5|          44|  1.0|\n",
      "|2887715|2019-11-01 19:00:00|2019|November|    1|Friday|  19|        3|   Melbourne Central|         2512|            1.0|           11|          5|          44|  1.0|\n",
      "|2887716|2019-11-01 19:00:00|2019|November|    1|Friday|  19|       15|       State Library|         1562|            0.0|           11|          5|          44|  0.0|\n",
      "|2887717|2019-11-01 19:00:00|2019|November|    1|Friday|  19|        9|Southern Cross St...|          522|            0.0|           11|          5|          44|  0.0|\n",
      "|2887718|2019-11-01 19:00:00|2019|November|    1|Friday|  19|       10|      Victoria Point|          126|            0.0|           11|          5|          44|  0.0|\n",
      "|2887719|2019-11-01 19:00:00|2019|November|    1|Friday|  19|       12|            New Quay|          385|            0.0|           11|          5|          44|  0.0|\n",
      "|2887720|2019-11-01 19:00:00|2019|November|    1|Friday|  19|       11|     Waterfront City|          123|            0.0|           11|          5|          44|  0.0|\n",
      "|2887721|2019-11-01 19:00:00|2019|November|    1|Friday|  19|        8|         Webb Bridge|          221|            0.0|           11|          5|          44|  0.0|\n",
      "|2887722|2019-11-01 19:00:00|2019|November|    1|Friday|  19|        7|      Birrarung Marr|          436|            0.0|           11|          5|          44|  0.0|\n",
      "|2887723|2019-11-01 19:00:00|2019|November|    1|Friday|  19|        5|      Princes Bridge|         2530|            1.0|           11|          5|          44|  1.0|\n",
      "|2887724|2019-11-01 19:00:00|2019|November|    1|Friday|  19|        6|Flinders Street S...|         2467|            1.0|           11|          5|          44|  1.0|\n",
      "|2887725|2019-11-01 19:00:00|2019|November|    1|Friday|  19|       14|    Sandridge Bridge|           38|            0.0|           11|          5|          44|  0.0|\n",
      "|2887726|2019-11-01 19:00:00|2019|November|    1|Friday|  19|       26|QV Market-Elizabe...|          698|            0.0|           11|          5|          44|  0.0|\n",
      "|2887727|2019-11-01 19:00:00|2019|November|    1|Friday|  19|       24|Spencer St-Collin...|         1566|            0.0|           11|          5|          44|  0.0|\n",
      "+-------+-------------------+----+--------+-----+------+----+---------+--------------------+-------------+---------------+-------------+-----------+------------+-----+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create udf to convert Months: January, February, March... to 1,2,3...\n",
    "def month_to_integer(s):\n",
    "    if s=='January':\n",
    "        return 1\n",
    "    elif s=='February':\n",
    "        return 2\n",
    "    elif s=='March':\n",
    "        return 3\n",
    "    elif s=='April':\n",
    "        return 4\n",
    "    elif s=='May':\n",
    "        return 5\n",
    "    elif s=='June':\n",
    "        return 6\n",
    "    elif s=='July':\n",
    "        return 7\n",
    "    elif s=='August':\n",
    "        return 8\n",
    "    elif s=='September':\n",
    "        return 9\n",
    "    elif s=='October':\n",
    "        return 10\n",
    "    elif s=='November':\n",
    "        return 11\n",
    "    else:\n",
    "        return 12\n",
    "\n",
    "month_to_integer_udf = udf(month_to_integer,IntegerType())\n",
    "\n",
    "# create a UDF to convert the Mondays, Tuesdays ... to 1,2....  \n",
    "def day_to_integer(s):\n",
    "    if s=='Monday':\n",
    "        return 1\n",
    "    elif s=='Tuesday':\n",
    "        return 2\n",
    "    elif s=='Wednesday':\n",
    "        return 3\n",
    "    elif s=='Thursday':\n",
    "        return 4\n",
    "    elif s=='Friday':\n",
    "        return 5\n",
    "    elif s=='Saturday':\n",
    "        return 6\n",
    "    else:\n",
    "        return 7\n",
    "\n",
    "day_to_integer_udf = udf(day_to_integer,IntegerType())\n",
    "\n",
    "# Add columns Month (in integer), day_of_week and week_of_year\n",
    "new_df = ped_counts_df.withColumn(\"Month_Integer\",month_to_integer_udf(ped_counts_df['Month']))\n",
    "new_df = new_df.withColumn(\"day_of_week\", day_to_integer_udf(new_df['Day']))\n",
    "new_df = new_df.withColumn(\"week_of_year\", weekofyear(new_df['Date_Time']))\n",
    "\n",
    "# filter data between 2014 to 2019 and only for hours between 9am to 11pm\n",
    "new_df = new_df.filter((new_df['Year'] >= 2014) & (new_df['Year'] <= 2019) & (new_df['Time'] >= 9) & (new_df['Time'] <= 23))\n",
    "\n",
    "# add label column for ml models' column later on\n",
    "new_df = new_df.withColumn(\"label\", new_df[\"above_threshold\"])\n",
    "new_df.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, LogisticRegression\n",
    "\n",
    "# Setting up the one hot encoder\n",
    "inputCols = ['Month_Integer', 'Mdate', 'week_of_year', 'day_of_week', 'Time', 'Sensor_ID']\n",
    "outputCols = [f'{x}_vec' for x in inputCols]\n",
    "encoder = OneHotEncoder(inputCols=inputCols,outputCols=outputCols, handleInvalid='keep')\n",
    "\n",
    "# Setting up the Vector Assembler\n",
    "inputColsAssembler = outputCols\n",
    "assembler = VectorAssembler(inputCols = inputColsAssembler, outputCol=\"features\")\n",
    "\n",
    "# Setting up Logistic Regression Model\n",
    "logistic_regression = LogisticRegression(labelCol='above_threshold', featuresCol='features')\n",
    "\n",
    "# Setting up Decision Tree \n",
    "decision_tree = DecisionTreeClassifier(labelCol='above_threshold', featuresCol = 'features')\n",
    "\n",
    "# Setting up Random Forest\n",
    "random_forest = RandomForestClassifier(labelCol='above_threshold', featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "lr_pipeline = Pipeline(stages=[encoder,assembler,logistic_regression])\n",
    "dt_pipeline = Pipeline(stages=[encoder,assembler,decision_tree])\n",
    "rf_pipeline = Pipeline(stages=[encoder,assembler,random_forest])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.2 Preparing the training data and testing data</h3>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data from 2014 to 2018 as training data\n",
    "train_df = new_df.filter((new_df['Year'] >= 2014) & (new_df['Year'] <= 2018))\n",
    "# Filter data from 2019 for testing purposes\n",
    "test_df = new_df.filter(new_df['Year'] == 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.3 Training and evaluating models</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+----------+\n",
      "|            features|above_threshold|prediction|\n",
      "+--------------------+---------------+----------+\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            1.0|       1.0|\n",
      "|(190,[11,14,89,10...|            1.0|       1.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            1.0|       1.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            1.0|       1.0|\n",
      "+--------------------+---------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+---------------+----------+\n",
      "|            features|above_threshold|prediction|\n",
      "+--------------------+---------------+----------+\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            1.0|       1.0|\n",
      "|(190,[11,14,89,10...|            1.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            1.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            1.0|       0.0|\n",
      "+--------------------+---------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+---------------+----------+\n",
      "|            features|above_threshold|prediction|\n",
      "+--------------------+---------------+----------+\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            1.0|       0.0|\n",
      "|(190,[11,14,89,10...|            1.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            1.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            0.0|       0.0|\n",
      "|(190,[11,14,89,10...|            1.0|       0.0|\n",
      "+--------------------+---------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and test logistic regression\n",
    "lr_model = lr_pipeline.fit(train_df)\n",
    "lr_predictions = lr_model.transform(test_df)\n",
    "lr_predictions.select('features','above_threshold','prediction').show()\n",
    "\n",
    "# Train and test decision tree\n",
    "dt_model = dt_pipeline.fit(train_df)\n",
    "dt_predictions = dt_model.transform(test_df)\n",
    "dt_predictions.select('features','above_threshold','prediction').show()\n",
    "\n",
    "# Train and test logistic regression\n",
    "rf_model = rf_pipeline.fit(train_df)\n",
    "rf_predictions = rf_model.transform(test_df)\n",
    "rf_predictions.select('features','above_threshold','prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model: \n",
      "+---------------+----------+------+\n",
      "|above_threshold|prediction| count|\n",
      "+---------------+----------+------+\n",
      "|            1.0|       1.0| 19728|\n",
      "|            0.0|       1.0|  6453|\n",
      "|            1.0|       0.0| 11313|\n",
      "|            0.0|       0.0|248038|\n",
      "+---------------+----------+------+\n",
      "\n",
      "Accuracy: 0.9377793031954387\n",
      "Precision: 0.7535235476108628\n",
      "Recall: 0.6355465352276022\n",
      "\n",
      "\n",
      "Decision Tree Model: \n",
      "+---------------+----------+------+\n",
      "|above_threshold|prediction| count|\n",
      "+---------------+----------+------+\n",
      "|            1.0|       1.0|  7683|\n",
      "|            0.0|       1.0|  6845|\n",
      "|            1.0|       0.0| 23358|\n",
      "|            0.0|       0.0|247646|\n",
      "+---------------+----------+------+\n",
      "\n",
      "Accuracy: 0.8942220136447053\n",
      "Precision: 0.528840859030837\n",
      "Recall: 0.24751135594858414\n",
      "\n",
      "\n",
      "Random Tree Model: \n",
      "+---------------+----------+------+\n",
      "|above_threshold|prediction| count|\n",
      "+---------------+----------+------+\n",
      "|            1.0|       0.0| 31041|\n",
      "|            0.0|       0.0|254491|\n",
      "+---------------+----------+------+\n",
      "\n",
      "Accuracy: 0.8912871411960831\n",
      "Precision: undefined\n",
      "Recall: 0.0\n"
     ]
    }
   ],
   "source": [
    "# function to compute the metrics of the predictions\n",
    "def compute_metrics(predictions):\n",
    "    values_df = predictions.groupBy(\"above_threshold\",\"prediction\").count()\n",
    "    values_df.show()\n",
    "    try:\n",
    "        TP = values_df.filter((values_df['above_threshold'] == 1.0)&(values_df['prediction']==1.0)).select(values_df['count']).collect()[0][0]\n",
    "    except:\n",
    "        TP = 0\n",
    "    try:\n",
    "        TN = values_df.filter((values_df['above_threshold'] == 0.0)&(values_df['prediction']==0.0)).select(values_df['count']).collect()[0][0]\n",
    "    except:\n",
    "        TN = 0\n",
    "    try:\n",
    "        FP = values_df.filter((values_df['above_threshold'] == 0.0)&(values_df['prediction']==1.0)).select(values_df['count']).collect()[0][0]\n",
    "    except:\n",
    "        FP = 0\n",
    "    try:\n",
    "        FN = values_df.filter((values_df['above_threshold'] == 1.0)&(values_df['prediction']==0.0)).select(values_df['count']).collect()[0][0]\n",
    "    except:\n",
    "        FN = 0\n",
    "        \n",
    "    # calculate metrics by the confusion matrix\n",
    "    accuracy = (TP+TN) / (TP+TN+FN+FP)    # formula to find accuracy\n",
    "    try:\n",
    "        precision = TP / (TP+FP)              # formula to find precision\n",
    "    except ZeroDivisionError:\n",
    "        precision = 'undefined'\n",
    "    recall = TP / (TP+FN)                 # formula to find recall\n",
    "    \n",
    "    print(\"Accuracy: \"+str(accuracy))\n",
    "    print(\"Precision: \"+str(precision))\n",
    "    print(\"Recall: \"+str(recall))\n",
    "    \n",
    "    return accuracy,precision,recall\n",
    "    \n",
    "# # Logistic Model \n",
    "print(\"Logistic Regression Model: \")\n",
    "metrics_calc_lr_df = lr_predictions.select('features', 'above_threshold','prediction')\n",
    "accuracy,precision,recall = compute_metrics(metrics_calc_lr_df)\n",
    "\n",
    "# Decision Tree Model\n",
    "print(\"\\n\\nDecision Tree Model: \")\n",
    "metrics_calc_dt_df = dt_predictions.select('features', 'above_threshold','prediction')\n",
    "accuracy,precision,recall = compute_metrics(metrics_calc_dt_df)\n",
    "\n",
    "# # Random Tree Model\n",
    "print(\"\\n\\nRandom Tree Model: \")\n",
    "metrics_calc_rf_df = rf_predictions.select('features', 'above_threshold','prediction')\n",
    "accuracy,precision,recall = compute_metrics(metrics_calc_rf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "<b>In terms of accuracy, Logistic Regression is a few percent better than the Decision Tree and Random Tree model which both have essentially the same accuracy. In terms of precision and recall, Logistic Regression is much better than the other two. The Decision Tree model suffers from low precision and recall. On the other hand, due to Random Tree model predicting everything as negative, its precision and recall is undefined and 0 respectively. This could be mainly attributed to the data imbalance of above and below threshold values we noticed before. \n",
    "\n",
    "Based on the performance metrics, it is clear that the Logistic Regression model is much better than the other two models as all three values of accuracy, precision and recall are higher than the other two. Therefore, we will persist with the Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist the pipeline model\n",
    "lr_fitted_mode.write().overwrite().save(\"pedestrian_prediction_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out/visualize the tree structure, and get the top-3 features with the corresponding feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_9adbe19f8eb1, depth=5, numNodes=49, numClasses=2, numFeatures=190\n",
      "  If (feature 169 in {1.0})\n",
      "   If (feature 130 in {1.0})\n",
      "    If (feature 104 in {1.0})\n",
      "     If (feature 98 in {1.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 98 not in {1.0})\n",
      "      If (feature 46 in {1.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 46 not in {1.0})\n",
      "       Predict: 1.0\n",
      "    Else (feature 104 not in {1.0})\n",
      "     If (feature 105 in {0.0})\n",
      "      If (feature 49 in {1.0})\n",
      "       Predict: 1.0\n",
      "      Else (feature 49 not in {1.0})\n",
      "       Predict: 0.0\n",
      "     Else (feature 105 not in {0.0})\n",
      "      If (feature 46 in {1.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 46 not in {1.0})\n",
      "       Predict: 1.0\n",
      "   Else (feature 130 not in {1.0})\n",
      "    If (feature 129 in {1.0})\n",
      "     If (feature 104 in {1.0})\n",
      "      If (feature 98 in {1.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 98 not in {1.0})\n",
      "       Predict: 1.0\n",
      "     Else (feature 104 not in {1.0})\n",
      "      If (feature 105 in {1.0})\n",
      "       Predict: 1.0\n",
      "      Else (feature 105 not in {1.0})\n",
      "       Predict: 0.0\n",
      "    Else (feature 129 not in {1.0})\n",
      "     Predict: 1.0\n",
      "  Else (feature 169 not in {1.0})\n",
      "   If (feature 135 in {1.0})\n",
      "    If (feature 116 in {1.0})\n",
      "     If (feature 39 in {0.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 39 not in {0.0})\n",
      "      If (feature 50 in {1.0})\n",
      "       Predict: 1.0\n",
      "      Else (feature 50 not in {1.0})\n",
      "       Predict: 0.0\n",
      "    Else (feature 116 not in {1.0})\n",
      "     If (feature 130 in {1.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 130 not in {1.0})\n",
      "      If (feature 129 in {1.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 129 not in {1.0})\n",
      "       Predict: 1.0\n",
      "   Else (feature 135 not in {1.0})\n",
      "    If (feature 134 in {1.0})\n",
      "     If (feature 116 in {1.0})\n",
      "      Predict: 0.0\n",
      "     Else (feature 116 not in {1.0})\n",
      "      If (feature 117 in {1.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 117 not in {1.0})\n",
      "       Predict: 1.0\n",
      "    Else (feature 134 not in {1.0})\n",
      "     If (feature 132 in {1.0})\n",
      "      If (feature 120 in {1.0})\n",
      "       Predict: 1.0\n",
      "      Else (feature 120 not in {1.0})\n",
      "       Predict: 0.0\n",
      "     Else (feature 132 not in {1.0})\n",
      "      If (feature 166 in {1.0})\n",
      "       Predict: 1.0\n",
      "      Else (feature 166 not in {1.0})\n",
      "       Predict: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the if-else tree structure\n",
    "decision_tree_model = dt_model.stages[2]\n",
    "print(decision_tree_model.toDebugString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>169</td>\n",
       "      <td>Sensor_ID_vec_38</td>\n",
       "      <td>0.218201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>135</td>\n",
       "      <td>Sensor_ID_vec_4</td>\n",
       "      <td>0.179074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>134</td>\n",
       "      <td>Sensor_ID_vec_3</td>\n",
       "      <td>0.167338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx              name     score\n",
       "169  169  Sensor_ID_vec_38  0.218201\n",
       "135  135   Sensor_ID_vec_4  0.179074\n",
       "134  134   Sensor_ID_vec_3  0.167338"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Function taken from lab 6: Used to extract the features and map it to their feature columns\n",
    "def ExtractFeatureImp(featureImp, dataset, featuresCol):\n",
    "    list_extract = []\n",
    "    for i in dataset.schema[featuresCol].metadata[\"ml_attr\"][\"attrs\"]:\n",
    "        list_extract = list_extract + dataset.schema[featuresCol].metadata[\"ml_attr\"][\"attrs\"][i]\n",
    "    varlist = pd.DataFrame(list_extract)\n",
    "    varlist['score'] = varlist['idx'].apply(lambda x: featureImp[x])\n",
    "    return(varlist.sort_values('score', ascending = False))\n",
    "\n",
    "# get the decision tree from the pipelined model\n",
    "decision_tree = dt_model.stages[2]\n",
    "# Print the top-3 features with each corresponding feature importance(represented by name and score respectively in the table below)\n",
    "ExtractFeatureImp(decision_tree.featureImportances, dt_predictions, \"features\").head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
