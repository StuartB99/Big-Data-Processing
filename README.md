# Big-Data-Processing
Everyday, 2.5 quintillion bytes of data are created and 90% of the data in the world today was created within the past two years! [IBM corporation, 2018] To manage these data with high volume, complexity and velocity, Pyspark and Kafka are used to explore the data and convert it into useful information.   
Each folder in the repository explores a different aspect of big data. The data used here revolves around pedestrian counts in Melbourne throughout the day. It is used to improve the traffic and facilitate better crowd control in the city. The data can be found in the [Google Drive link](https://drive.google.com/drive/folders/1KvRUwIPzOIVUYzZ8dM_-ZQz9SjQutvkw?usp=sharing).
